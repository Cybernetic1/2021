% TO-DO:

\input{../YKY-preamble.tex}

\usepackage{color}
\usepackage{mathtools}
\usepackage{hyperref}

\usepackage[backend=biber,style=numeric]{biblatex}
\bibliography{../AGI-book}
% \renewcommand*{\bibfont}{\footnotesize}

\usepackage{graphicx} % Allows including images
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage[export]{adjustbox}% http://ctan.org/pkg/adjustbox
\usepackage{verbatim} % for comments
% \usepackage{tikz-cd}  % commutative diagrams
% \newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}
% \usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
% \usepackage{amssymb}  % \leftrightharpoons
% \usepackage{wasysym} % frownie face
% \usepackage{newtxtext,newtxmath}	% Times New Roman font
% \usepackage{sansmath}

\numberwithin{equation}{subsection}

\newcommand{\underdash}[1]{%
	\tikz[baseline=(toUnderline.base)]{
		\node[inner sep=1pt,outer sep=10pt] (toUnderline) {#1};
		\draw[dashed] ([yshift=-0pt]toUnderline.south west) -- ([yshift=-0pt]toUnderline.south east);
	}%
}%

\DeclareSymbolFont{symbolsC}{U}{txsyc}{m}{n}
\DeclareMathSymbol{\strictif}{\mathrel}{symbolsC}{74}

\newcommand{\highlight}[1]{\colorbox{pink}{$\displaystyle #1$}}

\newcommand{\emp}[1]{{\color{violet}\textbf{#1}}}
\newcommand*\confoundFace{$\vcenter{\hbox{\includegraphics[scale=0.2]{../confounded-face.jpg}}}$}

\newcommand{\witness}{\scalebox{0.6}{$\blacksquare$}}
% \newcommand{\Heytingarrow}{\mathrel{-}\mathrel{\triangleright}}
\providecommand\Heytingarrow{\relbar\joinrel\mathrel{\vcenter{\hbox{\scalebox{0.75}{$\rhd$}}}}}

\begin{document}

% \title{\vspace*{-3cm}
% \cc{\bfseries\color{blue}{\Huge }}
% {{\Huge}}}
% \author{} % Your name
%\institute[] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
%{
%Independent researcher, Hong Kong \\ % Your institution for the title page
%\medskip
%\textit{generic.intelligence@gmail.com} % Your email address
%}
% \date{\today} % Date, can be changed to a custom date

% \maketitle

\today

{\small Applying for: \textbf{PhD program}}

\begin{center}
	\rule{0.8\textwidth}{1pt}
\end{center}

Dear CUHK professor(s),

I think I may be a suitable candidate for your research projects as I have a lot of experience in AI, deep learning, and natural language processing (in particular logic and inference).

I have been doing independent research in AGI (artificial general intelligence) since 2004 when I got back from studying in the US.  I have a bachelor's degree, but no master's or PhD qualification.

But I think I have extensive knowledge in the domains you cited.  

I have been working on the architecture of AGI for > 16 years.  AGI is the research that tries to build human-level intelligence.  My theory is based on a fusion of old-fashioned logic-based AI and the newly-emerged deep learning.

My latest theory posits that the state of an AI system be represented as a set of logic propositions which are invariant under permutations (because the logic conjunction $A \wedge B$ is commutative) and inference steps are performed by so-called \textbf{symmetric} neural networks which were invented (by others) in 2017-18.  Such a system has logic-reasoning ability that may be useful in diverse areas (eg. combining visual objection recognition with language abilities such as relational reasoning).  My theory also provides an interpretation of the mysterious ``attention mechanism'' in the famous BERT model, as a kind of alternative logic, via the Curry-Howard isomorphism.

I am now working on furthering this line of research:  the structure of logic is succinctly described by category / topos theory, this high level of abstraction facilitates transferring the logical structure to deep learning.  (I have been trying many ideas in this direction, but so far not met with success...)

Re tensor networks, it is interesting that I discovered that the AI learning problem (as reinforcement learning, or dynamic programming) is equivalent to solving the Schr\"{o}dinger equation in quantum mechanics.  However, this connection may not be highly useful because the bottleneck of learning seems to occur within the transition function of the dynamics.  I browsed through an introduction to tensor networks (TNs), and found that TNs are mainly concerned with representing the \textbf{coefficients} of many-body quantum wave functions rather than solving the wave functions themselves.  So, at least in this respect, TN is not directly relevant to my AI model, but you may have more interesting ideas that I'd be eager to learn about.



\section*{My CV}

\begin{itemize}
	\item In 2019 I discovered that logic structure can be imposed on deep learning by using \textbf{symmetric} neural networks, which emulate the permutation-invariance of logic propositions.
	\item In 2017 I discovered a connection between AI and quantum mechanics: the learning problem in AI is equivalent to solving the Schr\"{o}dinger equation.  But the key idea leading to this insight, ie. the Hamilton-Jacobi-Bellman equation, is already well-known in the literature.

	\item around 2014 I turned towards neural networks for AGI, at the time ``deep learning'' was not yet very popular (ReLU was demonstrated in 2011, Word2Vec was invented in 2013)
	\item 2012 my first and only published paper so far: "Fuzzy-probabilistic logic for common sense", in AGI Conference, Oxford.
	\item from 2004 till 2014 my research focused on classical logic-based AI and I implemented several logic engines
	\item around 2001-2003 I self-taught neuroscience

	\item 我在 GitHub 上有不少项目，包括：
	\begin{itemize}
		\item a few logic engines (in Lisp, Scala, Clojure, etc)
		\item implementation of rete algorithm (cloned from others and improved by me)
		\item genetic algorithm for learning logic rules
		\item simple deep learning experiments (using TensorFlow)
		\item neural network experiments (C++)
		\item a book draft, "Introduction to Strong AI" (Latex)
		\item symmetric neural network tests (TensorFlow \& python code)
	\end{itemize}

	\item 2004 graduated from Hofstra Univ, NY, USA, with BA degree in computer science, chemistry, and English
	\item 1994 majored in Computer Science in CUHK
	\item 我细个12岁时玩电脑已经几叻
	\item 1971 Born
\end{itemize}

% \tableofcontents
% \vspace*{0.5cm}
% 多谢 支持 \smiley

% \setcounter{section}{-1}
% \section{Background}

\section*{References}
% \cc{欢迎提问和讨论}{Questions, comments welcome} \smiley \\ \vspace*{0.4cm}
% \printbibliography

\end{document} 
